{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from pointnet import PointNetDenseCls\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from show3d_balls import *\n",
    "from dataset_provider import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset('./dataset', './tool_categories.txt', 2500, 'knife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2/513\n",
      "torch.Size([2500, 3]) torch.Size([2500])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# visualizing segmentation \n",
    "\n",
    "# model number which is used -> has to be the same as seg_model number (so if idx 2 then seg_model_2.pth)\n",
    "idx = 2\n",
    "\n",
    "print(\"model %d/%d\" %( idx, len(d)))\n",
    "\n",
    "point, seg = d[idx]\n",
    "\n",
    "print(point.size(), seg.size())\n",
    "\n",
    "point_np = point.numpy()\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"hsv\", 10)\n",
    "cmap = np.array([cmap(i) for i in range(10)])[:,:3]\n",
    "gt = cmap[seg.numpy() - 1, :]\n",
    "\n",
    "\n",
    "\"\"\" k is number of categories in our case 7\n",
    "  1 - 'grasp'\n",
    "  2 - 'cut'\n",
    "  3 - 'scoop'\n",
    "  4 - 'contain'\n",
    "  5 - 'pound'\n",
    "  6 - 'support'\n",
    "  7 - 'wrap-grasp'\n",
    "\"\"\"\n",
    "classifier = PointNetDenseCls(k = 7)\n",
    "classifier.load_state_dict(torch.load('seg/seg_model_2.pth'))\n",
    "classifier.eval()\n",
    "\n",
    "point = point.transpose(1,0).contiguous()\n",
    "\n",
    "point = Variable(point.view(1, point.size()[0], point.size()[1]))\n",
    "pred, _ = classifier(point)\n",
    "pred_choice = pred.data.max(2)[1]\n",
    "print(pred_choice)\n",
    "\n",
    "#print(pred_choice.size())\n",
    "pred_color = cmap[pred_choice.numpy()[0], :]\n",
    "\n",
    "#print(pred_color.shape)\n",
    "showpoints(point_np, gt, pred_color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
