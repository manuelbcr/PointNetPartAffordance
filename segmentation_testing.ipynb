{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== Previous Code(with small change) from Dataset Provider bellow ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open3d import *\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_directory_names(filename):\n",
    "    \n",
    "    directory_list = []\n",
    "    \n",
    "    file = open(filename, 'r') \n",
    "    lines = file.readlines() \n",
    "\n",
    "    for line in lines: \n",
    "        line_string = line.strip()\n",
    "        split_string = line_string.split(\" \", 2)\n",
    "        \n",
    "        directory_list.append(split_string[1])\n",
    "        \n",
    "    return directory_list\n",
    "\n",
    "\n",
    "# get all filenames in a given folder \n",
    "\n",
    "def get_all_filenames_from_directory(directory_path):\n",
    "    onlyfiles = [f for f in listdir(directory_path) if isfile(join(directory_path, f))]\n",
    "    \n",
    "    onlyfiles.sort()\n",
    "    \n",
    "    return onlyfiles\n",
    "\n",
    "\n",
    "def seperate_file_list_into_pcd_and_label(file_list):\n",
    "    \n",
    "    file_list.sort()\n",
    "    \n",
    "    pcd_list = [];\n",
    "    label_list = []\n",
    "    \n",
    "    suffix_pcd = \".pcd\"\n",
    "    suffix_mat = \".mat\"\n",
    "    \n",
    "    for file in file_list:\n",
    "        \n",
    "        if(file.endswith(suffix_pcd)):\n",
    "            pcd_list.append(file)\n",
    "            \n",
    "        if(file.endswith(suffix_mat)):\n",
    "            label_list.append(file)\n",
    "            \n",
    "    \n",
    "    pcd_list.sort()\n",
    "    label_list.sort()\n",
    "    \n",
    "    return pcd_list, label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_root, dataset_folders, number_of_points, categories):\n",
    "        \n",
    "        self.dataset_root = dataset_root\n",
    "        \n",
    "        # list of folders in root folder\n",
    "        self.dataset_folders = load_directory_names(dataset_folders)\n",
    "        self.categories = categories\n",
    "        self.number_of_points = number_of_points\n",
    "        \n",
    "        self.pointcloud_list = []\n",
    "        self.label_list = []\n",
    "        \n",
    "        # load labels and pointclouds into self.pointcloud_list and self.label_list\n",
    "        self.load_point_clouds()\n",
    "        \n",
    "        \n",
    "    def load_point_clouds(self):\n",
    "        \n",
    "        # iterate over all folders\n",
    "        for folder in self.dataset_folders:\n",
    "            \n",
    "            for j in range(0,len(self.categories)):\n",
    "                # if first part of folder name equals category name\n",
    "                if(folder.split('_')[0] == self.categories[j]):\n",
    "                    # get all filenames in given folder\n",
    "                    file_list = get_all_filenames_from_directory(self.dataset_root + '/' + folder)\n",
    "                    \n",
    "                    pcd_files, label_files = seperate_file_list_into_pcd_and_label(file_list)\n",
    "                    \n",
    "                    # iterate over all files in folder, already ensured that pcd_files and label_files have same length\n",
    "                    for i in range (0, int(len(pcd_files))):\n",
    "                        \n",
    "                        # load pointcloud\n",
    "                        pcd = open3d.io.read_point_cloud(self.dataset_root + '/' + folder + '/' + pcd_files[i])\n",
    "                        # load labels\n",
    "                        labels = loadmat(self.dataset_root + '/' + folder + '/' + label_files[i])\n",
    "                        \n",
    "                        self.pointcloud_list.append(pcd)\n",
    "                        self.label_list.append(labels)\n",
    "                        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        labels = self.label_list[index]['data'][0]\n",
    "        points = np.array(self.pointcloud_list[index].points)\n",
    "        \n",
    "        # randomly choose number of points form point cloud and labels \n",
    "        choice = np.random.choice(len(points), self.number_of_points, replace=True)\n",
    "        \n",
    "        points = points[choice, :]\n",
    "        labels = labels[choice]\n",
    "        \n",
    "        points = points.astype(np.float32)\n",
    "\n",
    "        torch_labels = torch.from_numpy(labels)\n",
    "        torch_points = torch.from_numpy(points)\n",
    "        choice=0\n",
    "        return torch_points, torch_labels \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pointcloud_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== Previous Code(with small change) from Dataset Provider above ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from pointnet import PointNetDenseCls\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, accuracy_score\n",
    "\n",
    "def evaluate_f_score(seg, pred):\n",
    "    \n",
    "    f1 = f1_score(seg, pred_choice[0], average='weighted')\n",
    "    precision = precision_score(seg, pred_choice[0], average='weighted')\n",
    "    accuracy = accuracy_score(seg, pred_choice[0])\n",
    "    \n",
    "    return f1, precision, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cat = {\n",
    "    \n",
    "    0 : ['bowl'],\n",
    "    1 : ['cup'],\n",
    "    2 : ['hammer'],\n",
    "    3 : ['knife'],\n",
    "    4 : ['ladle'],\n",
    "    5 : ['mallet'],\n",
    "    6 : ['mug'],\n",
    "    7 : ['saw'],\n",
    "    8 : ['scissors'],\n",
    "    9 : ['scoop'],\n",
    "    10 : ['shears'],\n",
    "    11 : ['shovel'],\n",
    "    12 : ['spoon'],\n",
    "    13 : ['tenderizer'],\n",
    "    14 : ['trowel'],\n",
    "    15 : ['turner'],   \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/manuel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/manuel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score for bowl: 0.7165847615606997\n",
      "Precision for bowl: 0.7213114754098361\n",
      "Accuracy for bowl: 0.7151159112825457\n",
      "F-score for cup: 0.9715515215824503\n",
      "Precision for cup: 0.9733141964175855\n",
      "Accuracy for cup: 0.970787476979741\n",
      "F-score for hammer: 0.8935661979380589\n",
      "Precision for hammer: 0.9025074491459129\n",
      "Accuracy for hammer: 0.8949225688073394\n",
      "F-score for knife: 0.9469881885625803\n",
      "Precision for knife: 0.954534201917379\n",
      "Accuracy for knife: 0.9475311657414747\n",
      "F-score for ladle: 0.5377185811473147\n",
      "Precision for ladle: 0.5654785957317834\n",
      "Accuracy for ladle: 0.5195141762452109\n",
      "F-score for mallet: 0.9183612884407893\n",
      "Precision for mallet: 0.9289441743799715\n",
      "Accuracy for mallet: 0.9157821782178212\n",
      "F-score for mug: 0.848262951678244\n",
      "Precision for mug: 0.8836224583784187\n",
      "Accuracy for mug: 0.8450979610330778\n",
      "F-score for saw: 0.16134809470019112\n",
      "Precision for saw: 0.1933479128503106\n",
      "Accuracy for saw: 0.16933831775700942\n",
      "F-score for scissors: 0.8914105218237915\n",
      "Precision for scissors: 0.9179839229802518\n",
      "Accuracy for scissors: 0.8888060301507525\n",
      "F-score for scoop: 0.07633751672265084\n",
      "Precision for scoop: 0.06441353193027642\n",
      "Accuracy for scoop: 0.12482972972972972\n",
      "F-score for shears: 0.9882433209924678\n",
      "Precision for shears: 0.988392301265053\n",
      "Accuracy for shears: 0.9884468085106379\n",
      "F-score for shovel: 0.20023715126016686\n",
      "Precision for shovel: 0.1923808961054961\n",
      "Accuracy for shovel: 0.23474666666666658\n",
      "F-score for spoon: 0.6803329119039494\n",
      "Precision for spoon: 0.7047963049743527\n",
      "Accuracy for spoon: 0.682335448275862\n",
      "F-score for tenderizer: 0.16028942096088994\n",
      "Precision for tenderizer: 0.1485630543508557\n",
      "Accuracy for tenderizer: 0.19158580645161288\n",
      "F-score for trowel: 0.21654566734836656\n",
      "Precision for trowel: 0.19635038577392985\n",
      "Accuracy for trowel: 0.29465557986870883\n",
      "F-score for turner: 0.7250892842550698\n",
      "Precision for turner: 0.7450932479727702\n",
      "Accuracy for turner: 0.7214784110535398\n"
     ]
    }
   ],
   "source": [
    "final_list = []\n",
    "\n",
    "for i in range (0, len(dict_cat)):     \n",
    "    \n",
    "    d = Dataset('./dataset', './tool_categories_test.txt', 2500, dict_cat[i])\n",
    "    \n",
    "    result_f = []\n",
    "    result_precision = []\n",
    "    result_accuracy = []\n",
    "\n",
    "    for j in range(0 , len(d)):\n",
    "\n",
    "        # get the points and segmentation\n",
    "        point, seg = d[j]\n",
    "\n",
    "        point_np = point.numpy()\n",
    "\n",
    "        \"\"\" k is number of categories in our case 7\n",
    "          1 - 'grasp'\n",
    "          2 - 'cut'\n",
    "          3 - 'scoop'\n",
    "          4 - 'contain'\n",
    "          5 - 'pound'\n",
    "          6 - 'support'\n",
    "          7 - 'wrap-grasp'\n",
    "        \"\"\"\n",
    "        # load segmentation model\n",
    "        classifier = PointNetDenseCls(k = 7)\n",
    "        classifier.load_state_dict(torch.load('seg_total/seg_model_34.pth', map_location=torch.device('cpu')))\n",
    "        classifier.eval()\n",
    "\n",
    "        point = point.transpose(1,0).contiguous()\n",
    "\n",
    "        # predict\n",
    "        point = Variable(point.view(1, point.size()[0], point.size()[1]))\n",
    "        pred, _ = classifier(point)\n",
    "        pred_choice = pred.data.max(2)[1]\n",
    "\n",
    "        # decrease all seg values -1 because seg values are from 1-7 and predicted values are from 0-6\n",
    "        seg = seg - 1\n",
    "        \n",
    "        f1 = 0.0\n",
    "        precision = 0.0\n",
    "        accuracy = 0.0\n",
    "\n",
    "        f1, precision, accuracy = evaluate_f_score(seg, pred_choice)\n",
    "        result_f.append(f1)\n",
    "        result_precision.append(precision)\n",
    "        result_accuracy.append(accuracy)\n",
    "    \n",
    "    \n",
    "    print(\"F-score for \" + dict_cat[i][0] + \": \" + str(sum(result_f)/len(result_f)))\n",
    "    print(\"Precision for \" + dict_cat[i][0] + \": \" + str(sum(result_precision)/len(result_precision)))\n",
    "    print(\"Accuracy for \" + dict_cat[i][0] + \": \" + str(sum(result_accuracy)/len(result_accuracy)))\n",
    "    final_list.append(sum(result_f)/len(result_f))\n",
    "    final_list.append(sum(result_precision)/len(result_precision))\n",
    "    final_list.append(sum(result_accuracy)/len(result_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
